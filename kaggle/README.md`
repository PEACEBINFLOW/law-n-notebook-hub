# Kaggle Integration

This folder tracks how the **Law-N Notebook Hub** maps into Kaggle:

- Which notebooks become Kaggle notebooks
- Which `datasets/*` folders become Kaggle datasets
- How to keep descriptions, tags, and links consistent

## Suggested flow

1. Build and iterate notebooks locally under `notebooks/core/...`.
2. Once stable, export/copy a version for Kaggle:
   - Keep the original in this repo
   - Use Kaggle to run it against mirrored datasets if needed
3. For each Kaggle asset, log it here:

| Type      | Kaggle name / URL              | Source notebook                          | Source dataset path        |
|-----------|--------------------------------|------------------------------------------|----------------------------|
| Notebook  | TBD                            | notebooks/core/signal-sim/01_*.ipynb     | datasets/processed/...     |
| Dataset   | TBD                            | (generated by) nsql-engine notebooks     | datasets/processed/...     |
| Model     | TBD                            | (future) N-SQL / Law-N pattern models    |                            |

You can use the templates in `metadata-templates/` as starting points when creating new Kaggle datasets or notebooks.
